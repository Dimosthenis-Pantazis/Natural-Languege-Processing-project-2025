{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1de540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e88e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ανακατασκευή Πρότασης 1: Today is our lives Hope you too to show our lives Hope you too to.\n",
      "Ανακατασκευή Πρότασης 2: During our Springer proceedings publication During our Springer proceedings publication During our Springer proceedings publication.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Κείμενα\n",
    "text1 = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
    "our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
    "I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication\"\"\"\n",
    "\n",
    "text2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since\n",
    "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
    "maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets\"\"\"\n",
    "\n",
    "# Συνένωση\n",
    "all_text = text1 + \" \" + text2\n",
    "\n",
    "# Διάσπαση σε λέξεις\n",
    "words = re.findall(r\"\\w+\", all_text)\n",
    "\n",
    "# Δημιουργία Markov chain\n",
    "markov_chain = defaultdict(list)\n",
    "for i in range(len(words) - 1):\n",
    "    markov_chain[words[i].lower()].append(words[i + 1])\n",
    "\n",
    "# Συνάρτηση δημιουργίας νέας πρότασης\n",
    "def generate_sentence(start_word, length=12):\n",
    "    word = start_word.lower()\n",
    "    sentence = [start_word.capitalize()]\n",
    "    for _ in range(length - 1):\n",
    "        if word not in markov_chain:\n",
    "            break\n",
    "        next_word = random.choice(markov_chain[word])\n",
    "        sentence.append(next_word)\n",
    "        word = next_word.lower()\n",
    "    return \" \".join(sentence) + \".\"\n",
    "\n",
    "# Δημιουργία 2 προτάσεων\n",
    "sentence1 = generate_sentence(\"today\", 15)\n",
    "sentence2 = generate_sentence(\"during\", 15)\n",
    "\n",
    "print(\"Ανακατασκευή Πρότασης 1:\", sentence1)\n",
    "print(\"Ανακατασκευή Πρότασης 2:\", sentence2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c892d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pipeline A: Markovify...\n",
      "Running Pipeline B: spaCy rule-based...\n",
      "Running Pipeline C: Transformer summarization/paraphrase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2f03b886a24fd38fe7011f754b16e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  20%|##        | 325M/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b0c0aea80f4521805dcc0613243041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10688dd09bb14946913986216da69276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2059e4170e47a2aa5d0b937ebbbfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f22a8857ea4554ab26da126904a8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 180, but your input_length is only 170. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\n",
      "Your max_length is set to 180, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "--- Reconstructions ---\n",
      "\n",
      "--- Markovify (A) ---\n",
      "\n",
      "Overall, let us make sure all are safe and great in our Chinese culture, to celebrate it with all safe and celebrate the outcome with strong coffee and future targets I am very appreciated the full feedback from reviewer or maybe I missed, I apologize if so. Also, kindly remind me please, if the doctor still plan for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acceptance and efforts until the Springer link came finally last week, I think. Thank your message to see the approved message. Also, kindly remind me please, if the doctor still plan for the acceptance and efforts until the Springer link came finally last week, I think. I got this message to show me, this, a couple of days ago.\n",
      "\n",
      "--- spaCy Rule-based (B) ---\n",
      "\n",
      "Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please\n",
      "\n",
      "--- Transformer (C) ---\n",
      "\n",
      "Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\n",
      "\n",
      "--- Metrics (higher better) ---\n",
      "\n",
      "Markovify A:\n",
      "{'rouge1_f': 0.579345088161209,\n",
      " 'rouge2_f': 0.4607594936708861,\n",
      " 'rougeL_f': 0.3022670025188917,\n",
      " 'semantic_cosine': 0.7867251038551331}\n",
      "\n",
      "spaCy Rule-based B:\n",
      "{'rouge1_f': 1.0, 'rouge2_f': 1.0, 'rougeL_f': 1.0, 'semantic_cosine': 1.0}\n",
      "\n",
      "Transformer C:\n",
      "{'rouge1_f': 0.5597484276729561,\n",
      " 'rouge2_f': 0.550632911392405,\n",
      " 'rougeL_f': 0.5597484276729561,\n",
      " 'semantic_cosine': 0.8335554599761963}\n",
      "\n",
      "Recommendations:\n",
      "- Transformer (C) usually yields the best semantic fidelity and coherence for this task.\n",
      "- spaCy (B) is valuable for rule-based, controllable rewrites without large models.\n",
      "- Markov (A) is useful for creative variants but not for faithful reconstruction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soni 18\\AppData\\Local\\Temp\\ipykernel_5208\\3046895521.py:131: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cos = float(np.dot(emb_orig, emb_recon.T) / (np.linalg.norm(emb_orig) * np.linalg.norm(emb_recon)))\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# file: reconstruct_pipelines.py\n",
    "# Path at top as requested.\n",
    "\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "import markovify\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "# --- Input texts (the originals) ---\n",
    "text1 = (\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in \"\n",
    "         \"our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. \"\n",
    "         \"I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. \"\n",
    "         \"I am very appreciated the full support of the professor, for our Springer proceedings publication\")\n",
    "\n",
    "text2 = (\"During our final discuss, I told him about the new submission — the one we were waiting since \"\n",
    "         \"last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? \"\n",
    "         \"Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. \"\n",
    "         \"We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. \"\n",
    "         \"Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. \"\n",
    "         \"Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets\")\n",
    "\n",
    "CORPUS = text1 + \"\\n\" + text2\n",
    "\n",
    "# --- Utility functions ---\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    s = re.sub(r\"\\s+\", ' ', s)\n",
    "    return s\n",
    "\n",
    "# --- Pipeline A: Markovify ---\n",
    "# Pros: simple, fast. Cons: poor semantics, can hallucinate.\n",
    "\n",
    "def pipeline_markov(corpus: str, sentences: int = 5, state_size: int = 2) -> str:\n",
    "    model = markovify.Text(corpus, state_size=state_size)\n",
    "    out = []\n",
    "    for _ in range(sentences):\n",
    "        s = model.make_sentence(tries=100)\n",
    "        if s:\n",
    "            out.append(s)\n",
    "    return ' '.join(out)\n",
    "\n",
    "# --- Pipeline B: spaCy rule-based rewriting ---\n",
    "# Heuristic approach: merge short sentences, remove repetitions, fix simple grammar issues.\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_sentence(sent: str) -> str:\n",
    "    # basic fixes: spacing, remove duplicate words sequences\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(r\"\\s+\", ' ', sent)\n",
    "    # remove repeated short phrases like 'the message the message'\n",
    "    sent = re.sub(r\"\\b(\\w+)(?:\\s+\\1\\b)+\", r\"\\1\", sent, flags=re.I)\n",
    "    return sent\n",
    "\n",
    "\n",
    "def pipeline_spacy_rule(corpus: str) -> str:\n",
    "    doc = nlp(corpus)\n",
    "    sentences = list(doc.sents)\n",
    "    combined = []\n",
    "    buffer = []\n",
    "    for sent in sentences:\n",
    "        s_text = clean_sentence(sent.text)\n",
    "        # if sentence short, buffer it to merge with next for coherence\n",
    "        if len(s_text.split()) < 8:\n",
    "            buffer.append(s_text)\n",
    "        else:\n",
    "            if buffer:\n",
    "                buffer.append(s_text)\n",
    "                combined.append(' '.join(buffer))\n",
    "                buffer = []\n",
    "            else:\n",
    "                combined.append(s_text)\n",
    "    if buffer:\n",
    "        combined.append(' '.join(buffer))\n",
    "\n",
    "    # Post-process: ensure punctuation and capitalization\n",
    "    out_sents = []\n",
    "    for s in combined:\n",
    "        s = s.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if s[-1] not in '.!?':\n",
    "            s = s + '.'\n",
    "        s = s[0].upper() + s[1:]\n",
    "        out_sents.append(s)\n",
    "    return ' '.join(out_sents)\n",
    "\n",
    "# --- Pipeline C: Transformer (Hugging Face seq2seq) ---\n",
    "# Use a summarization/paraphrase model via pipeline('text2text-generation' or 'summarization')\n",
    "\n",
    "# NOTE: model downloads occur on first run. Choose a medium-sized model for balance.\n",
    "\n",
    "def pipeline_transformer_paraphrase(corpus: str, model_name: str = 'facebook/bart-large-cnn') -> str:\n",
    "    summarizer = pipeline('summarization', model=model_name)\n",
    "    # split into chunks if corpus long\n",
    "    max_chunk = 800\n",
    "    chunks = []\n",
    "    text = normalize_text(corpus)\n",
    "    while text:\n",
    "        chunk = text[:max_chunk]\n",
    "        # try to cut at sentence end\n",
    "        last = chunk.rfind('.')\n",
    "        if last != -1 and last > int(max_chunk * 0.6):\n",
    "            chunk = chunk[:last+1]\n",
    "        chunks.append(chunk)\n",
    "        text = text[len(chunk):].lstrip()\n",
    "    results = []\n",
    "    for c in chunks:\n",
    "        res = summarizer(c, max_length=180, min_length=40, do_sample=False)\n",
    "        results.append(res[0]['summary_text'])\n",
    "    return ' '.join(results)\n",
    "\n",
    "# --- Evaluation metrics ---\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "def evaluate_reconstruction(original: str, reconstructed: str) -> dict:\n",
    "    # ROUGE: compare the two texts\n",
    "    rouge_scores = scorer.score(original, reconstructed)\n",
    "    # semantic similarity: compute embedding cosine similarity\n",
    "    emb_orig = sbert_model.encode([original], convert_to_numpy=True)\n",
    "    emb_recon = sbert_model.encode([reconstructed], convert_to_numpy=True)\n",
    "    cos = float(np.dot(emb_orig, emb_recon.T) / (np.linalg.norm(emb_orig) * np.linalg.norm(emb_recon)))\n",
    "    return {\n",
    "        'rouge1_f': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2_f': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL_f': rouge_scores['rougeL'].fmeasure,\n",
    "        'semantic_cosine': cos\n",
    "    }\n",
    "\n",
    "# --- Run all pipelines and evaluate ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    corpus = normalize_text(CORPUS)\n",
    "\n",
    "    print('Running Pipeline A: Markovify...')\n",
    "    recon_a = pipeline_markov(corpus, sentences=8, state_size=2)\n",
    "\n",
    "    print('Running Pipeline B: spaCy rule-based...')\n",
    "    recon_b = pipeline_spacy_rule(corpus)\n",
    "\n",
    "    print('Running Pipeline C: Transformer summarization/paraphrase...')\n",
    "    recon_c = pipeline_transformer_paraphrase(corpus, model_name='facebook/bart-large-cnn')\n",
    "\n",
    "    # Evaluate against concatenated original (we treat the reconstruction goal as preserving overall meaning)\n",
    "    original_concat = normalize_text(text1) + ' ' + normalize_text(text2)\n",
    "\n",
    "    print('\\nEvaluating...')\n",
    "    eval_a = evaluate_reconstruction(original_concat, recon_a)\n",
    "    eval_b = evaluate_reconstruction(original_concat, recon_b)\n",
    "    eval_c = evaluate_reconstruction(original_concat, recon_c)\n",
    "\n",
    "    # Present concise comparison\n",
    "    from pprint import pprint\n",
    "    print('\\n--- Reconstructions ---\\n')\n",
    "    print('--- Markovify (A) ---\\n')\n",
    "    print(recon_a[:1000])\n",
    "    print('\\n--- spaCy Rule-based (B) ---\\n')\n",
    "    print(recon_b[:1000])\n",
    "    print('\\n--- Transformer (C) ---\\n')\n",
    "    print(recon_c[:1000])\n",
    "\n",
    "    print('\\n--- Metrics (higher better) ---\\n')\n",
    "    print('Markovify A:')\n",
    "    pprint(eval_a)\n",
    "    print('\\nspaCy Rule-based B:')\n",
    "    pprint(eval_b)\n",
    "    print('\\nTransformer C:')\n",
    "    pprint(eval_c)\n",
    "\n",
    "    # Short recommendations based on metrics\n",
    "    print('\\nRecommendations:')\n",
    "    # typically transformer will have best semantic similarity and ROUGE, spaCy will give most grammatical control,\n",
    "    # Markovify is fast but lowest semantic accuracy.\n",
    "    print('- Transformer (C) usually yields the best semantic fidelity and coherence for this task.')\n",
    "    print('- spaCy (B) is valuable for rule-based, controllable rewrites without large models.')\n",
    "    print('- Markov (A) is useful for creative variants but not for faithful reconstruction.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "033bf6bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sumy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msumy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplaintext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PlaintextParser\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msumy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msumy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_rank\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextRankSummarizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sumy'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Κείμενα\n",
    "text1 = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication.\"\"\"\n",
    "\n",
    "text2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\"\"\"\n",
    "\n",
    "all_texts = [text1, text2]\n",
    "\n",
    "# --- Pipeline 1: spaCy cleanup ---\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def spacy_reconstruct(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip().capitalize() for sent in doc.sents]\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "# --- Pipeline 2: Sumy TextRank summarizer ---\n",
    "def textrank_reconstruct(text):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, 5)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# --- Pipeline 3: Transformers paraphrase/summarization ---\n",
    "summarizer_hf = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "def hf_reconstruct(text):\n",
    "    result = summarizer_hf(text, max_length=120, min_length=40, do_sample=False)\n",
    "    return result[0]['summary_text']\n",
    "\n",
    "# Ανακατασκευή για κάθε κείμενο\n",
    "reconstructed_texts = []\n",
    "for i, txt in enumerate(all_texts, start=1):\n",
    "    print(f\"===== Κείμενο {i} =====\")\n",
    "    print(\"--- spaCy ---\")\n",
    "    spa_out = spacy_reconstruct(txt)\n",
    "    print(spa_out)\n",
    "    print(\"\\n--- Sumy TextRank ---\")\n",
    "    sumy_out = textrank_reconstruct(txt)\n",
    "    print(sumy_out)\n",
    "    print(\"\\n--- Transformers ---\")\n",
    "    hf_out = hf_reconstruct(txt)\n",
    "    print(hf_out)\n",
    "    print(\"\\n\")\n",
    "    reconstructed_texts.append({\n",
    "        \"spacy\": spa_out,\n",
    "        \"sumy\": sumy_out,\n",
    "        \"transformers\": hf_out\n",
    "    })\n",
    "\n",
    "# --- Εκτύπωση τελικού συγκεντρωτικού κειμένου ---\n",
    "print(\"===== Τελική Ανακατασκευή Κειμένων =====\")\n",
    "for i, recon in enumerate(reconstructed_texts, start=1):\n",
    "    print(f\"Κείμενο {i} (spaCy): {recon['spacy']}\\n\")\n",
    "    print(f\"Κείμενο {i} (Sumy TextRank): {recon['sumy']}\\n\")\n",
    "    print(f\"Κείμενο {i} (Transformers): {recon['transformers']}\\n\")\n",
    "\n",
    "# --- Σύγκριση ---\n",
    "print(\"===== Συγκριτική Αξιολόγηση =====\")\n",
    "print(\"spaCy: Διατηρεί σχεδόν όλο το κείμενο, με καλύτερη στίξη και καθαρότητα.\")\n",
    "print(\"Sumy TextRank: Περιορίζει το κείμενο σε λίγες βασικές προτάσεις, αλλά μπορεί να χάσει λεπτομέρειες.\")\n",
    "print(\"Transformers: Δίνει αναδιατυπωμένη, πιο συνοπτική εκδοχή με καλύτερη συνοχή και ροή.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
