# Εργασία Ανάλυσης Φυσικής γλώσσας 2025 


## Εισαγωγή:
Ο λόγος που χρησιμοποιούμε σημασιολογική ανακατασκευή είναι διότι βοηθά στην βελτίωση της γραμματικής των κειμένων, στην διαμόρφωση των κειμένων όσο αφορά την έκφραση και την διατήρηση του αρχικού νοήματος. Το NLP είναι υπεύθυνο για την χρήση αυτομάτων παραφράσεων pipelines ( T5, Pegasus, BART)  και αξιολόγηση τους με βάση σκορ (Π.χ bleu, rouge, cosine). Επίσης, μέσω embeddings δημιουργεί δενδρόγραμμα και PCA/t-SNE για ευκολία κατανόησης των αποτελεσμάτων.

## Μεθοδολογία:
  Για το Α χρησιμοποιήθηκαν χειροποίητες γλωσσικές αντικαταστάσεις με βάση τη γραμματική.
  Για το Β χρησιμοποιήθηκαν seq2seq μοντέλα με στόχο τη δημιουργία πιο φυσικών εκδοχών προσφέροντας παραλλαγές στο ύφος και ροή παράλληλα  διατηρώντας το νόημα. 
  Για το C αξιοποιήθηκαν διάφορες συγκρίσεις κειμένου, ποιο συγκεκριμένα: 
    - BLEU: overlap σε n-grams.
    - ROUGE: recall/precision σε λέξεις/φράσεις.
    - Cosine Similarity με BERT: μετρά σημασιολογική εγγύτητα με βάση τα embeddings.
  Για να το επιτύχουμε μια τεχνική που εφαρμόσαμε είναι η συνάφεια συνημιτόνου
  με τύπο cos(x)= (A*B)/(|A| * |B|)

## Πειράματα & Αποτελέσματα:

Μπορείτε να βρείτε παραδείγματα πριν/μετά την ανακατασκευή στα παρακάτω αρχεία: 
1. A_viz_bert_pca.png
2. A_viz_bert_tsne.png
3. B_viz_bert_pca.png
4. B_viz_bert_tsne.png


## Συζήτηση:
Με βάση τα αποτελέσματα του cosine, παρατηρούμε ότι αποτυπώθηκαν με μεγάλη ευστοχία   το νόημα των κειμένων, όμως το Word2Vec / GloVe παρουσίασε δυσκολίες λόγου του περιορισμένου pool δεδομένων. 
 Μερικές προκλήσεις κατά την ανακατασκευή  ήταν τα συντακτικά λάθη και οι παραφράσεις που άλλαζαν το νόημα. 
 Η αυτοματοποίηση της διαδικασίας μέσω NLP θα απαιτούσε το συνδυασμό πολλαπλών σταδίων σε ένα ενιαίο pipeline. Ακόμα, το pipeline  θα έπρεπε να είναι ικανό να περιέχει ενσωματωμένο μέτρα αξιολόγησης όπως bleu και rouge και άλλες τεχνικές όπως PCA, t-SNE για την απεικόνιση τους.
 Υπήρξε ένας μεγάλος αριθμός διαφορών στην ποιότητα ανακατασκευής μεταξύ τεχνικών και βιβλιοθηκών.
χειροκίνητη ανακατασκευή: Οι χειροποίητοι κανόνες στόχευαν συγκεκριμένα σημεία των προτάσεων και παρείχαν αρκετά περιορισμένοι κάλυψη.

  - παραφραστικά μοντέλα: Τα μοντέλα δημιουργούσαν περισσότερο φυσικές ανακατασκευές αλλά το κάθε μοντέλο είχε διαφορετική προσέγγιση. Το humarin προτιμούσε ποιο "ελεύθερες" διατυπώσεις, το Pegasus εξειδικευόταν σε μικρές προτάσεις σε αντίθεση με το BART που παρήγαγε μεγαλύτερες σε μέγεθος παραλλαγές.
  - Ενσωματωμένες λέξεις:  Τα Word2Vec και FastText αντιμετώπιζαν με ευκολία λέξεις  προς λέξεις όμως έχαναν το συνολικό νόημα, σε αντίθεση με τα BERT embeddings που παρουσίαζαν σημασιολογική συνάφεια σε επίπεδο πρότασης.

## Συμπέρασμα:
Συμπεραίνοντας,  η σημασιολογική ανακατασκευή είναι μια περίπλοκη διαδικασία με κάθε προσέγγιση να έχουν πλεονεκτήματα και μειονεκτήματα. Οι κανόνες είναι αποτελεσματικοί για στοχευμένα τμήματα και λάθη αλλά είναι ανεπαρκείς για πολύπλοκα κείμενα. Τα μοντέλα NLP παρήγαγα φυσικά κείμενα και τα context-free μοντέλα (Word2Vec, FastText, GloVe) περιορίζονται σe τοπικό επίπεδο, ενώ τα context-sensitive embeddings (BERT) απέδωσαν καλύτερα την ολική σημασιολογία και τη συνάφεια προτάσεων. Βασική πρόκληση ήταν διατήρηση του αρχικού νοήματος των κειμένων και η διόρθωση συντακτικών λαθών.

## Βιβλιογραφία:
[Hugging face](https://huggingface.co/)

